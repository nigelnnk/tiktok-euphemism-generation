{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "4LBv95lL_WMy",
        "jmse5KnI_QxR"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "premium",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "258ae576ba564c0fa4bf87babcf639fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e583ef4f9a7e4998ac5a81248b7f242d",
              "IPY_MODEL_be4734c6794940bdb4d7e93f1605a55d",
              "IPY_MODEL_30735375d6b8446a9ec54e8c395d4d9e"
            ],
            "layout": "IPY_MODEL_ff65fb5f92124810a804e7a2f0e7a109"
          }
        },
        "e583ef4f9a7e4998ac5a81248b7f242d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_423af480d48d44b68fba49d62382b1ab",
            "placeholder": "​",
            "style": "IPY_MODEL_21f1e9c96d9e46e59acde11a7a3a107e",
            "value": "100%"
          }
        },
        "be4734c6794940bdb4d7e93f1605a55d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32399539c586489aa51a0759391dc706",
            "max": 31807,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7704fde6d2240968891f07bad597042",
            "value": 31807
          }
        },
        "30735375d6b8446a9ec54e8c395d4d9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e35d7c763c0742fd8051478245dcebac",
            "placeholder": "​",
            "style": "IPY_MODEL_fbaf18e597a14d1cb52cfdcb30913369",
            "value": " 31807/31807 [00:00&lt;00:00, 106306.18it/s]"
          }
        },
        "ff65fb5f92124810a804e7a2f0e7a109": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "423af480d48d44b68fba49d62382b1ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21f1e9c96d9e46e59acde11a7a3a107e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32399539c586489aa51a0759391dc706": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7704fde6d2240968891f07bad597042": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e35d7c763c0742fd8051478245dcebac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbaf18e597a14d1cb52cfdcb30913369": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4Q6usoSwUh6"
      },
      "source": [
        "In this notebook, we demonstrate how to extract and lookup for contextually-most-similar words using BERT and nearest neighbor search. \n",
        "\n",
        "This was inspired by the StackOverflow question https://stackoverflow.com/questions/59865719/how-to-find-the-closest-word-to-a-vector-using-bert"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: The environment we use is google colab, first run. Subsequent runs after reset have had issues with dependencies."
      ],
      "metadata": {
        "id": "ZveD1Oe68wCi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ul0lMapo0T3"
      },
      "source": [
        "# learn to extract embeddings from bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTeM3tJxhDd6"
      },
      "source": [
        "We use `bert-embedding` package; see https://pypi.org/project/bert-embedding/\n",
        "\n",
        "We use GPU, so please choose the Colab kernel accordingly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7EZJcvygjTI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aefc0afb-9893-4d1a-a613-7d824c93b472"
      },
      "source": [
        "!pip install mxnet-cu102\n",
        "!pip install bert-embedding"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mxnet-cu102\n",
            "  Downloading mxnet_cu102-1.9.1-py3-none-manylinux2014_x86_64.whl (380.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 380.8 MB 6.1 kB/s \n",
            "\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu102) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu102) (1.21.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu102) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu102) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu102) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu102) (3.0.4)\n",
            "Installing collected packages: graphviz, mxnet-cu102\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-cu102-1.9.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bert-embedding\n",
            "  Downloading bert_embedding-1.0.1-py3-none-any.whl (13 kB)\n",
            "Collecting typing==3.6.6\n",
            "  Downloading typing-3.6.6-py3-none-any.whl (25 kB)\n",
            "Collecting mxnet==1.4.0\n",
            "  Downloading mxnet-1.4.0-py2.py3-none-manylinux1_x86_64.whl (29.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 29.6 MB 103.5 MB/s \n",
            "\u001b[?25hCollecting numpy==1.14.6\n",
            "  Downloading numpy-1.14.6-cp37-cp37m-manylinux1_x86_64.whl (13.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.8 MB 62.5 MB/s \n",
            "\u001b[?25hCollecting gluonnlp==0.6.0\n",
            "  Downloading gluonnlp-0.6.0.tar.gz (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 52.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet==1.4.0->bert-embedding) (0.8.4)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet==1.4.0->bert-embedding) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->mxnet==1.4.0->bert-embedding) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->mxnet==1.4.0->bert-embedding) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->mxnet==1.4.0->bert-embedding) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->mxnet==1.4.0->bert-embedding) (1.24.3)\n",
            "Building wheels for collected packages: gluonnlp\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.6.0-py3-none-any.whl size=259930 sha256=8240234c55c300214ba60c5a84300722430138fac2d524b17e83cebf261b7c7a\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/41/8f/45bd1c58055d87aee5a71b6756a427ea8d92e506b3a9d17370\n",
            "Successfully built gluonnlp\n",
            "Installing collected packages: numpy, typing, mxnet, gluonnlp, bert-embedding\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.5 requires numpy>=1.16.0, but you have numpy 1.14.6 which is incompatible.\n",
            "xarray 0.20.2 requires numpy>=1.18, but you have numpy 1.14.6 which is incompatible.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.14.6 which is incompatible.\n",
            "tifffile 2021.11.2 requires numpy>=1.15.1, but you have numpy 1.14.6 which is incompatible.\n",
            "thinc 8.1.5 requires numpy>=1.15.0, but you have numpy 1.14.6 which is incompatible.\n",
            "tensorflow 2.9.2 requires numpy>=1.20, but you have numpy 1.14.6 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.14.6 which is incompatible.\n",
            "statsmodels 0.12.2 requires numpy>=1.15, but you have numpy 1.14.6 which is incompatible.\n",
            "spacy 3.4.3 requires numpy>=1.15.0, but you have numpy 1.14.6 which is incompatible.\n",
            "seaborn 0.11.2 requires numpy>=1.15, but you have numpy 1.14.6 which is incompatible.\n",
            "scipy 1.7.3 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.14.6 which is incompatible.\n",
            "scikit-image 0.18.3 requires numpy>=1.16.5, but you have numpy 1.14.6 which is incompatible.\n",
            "resampy 0.4.2 requires numpy>=1.17, but you have numpy 1.14.6 which is incompatible.\n",
            "pywavelets 1.3.0 requires numpy>=1.17.3, but you have numpy 1.14.6 which is incompatible.\n",
            "pymc 4.1.4 requires numpy>=1.15.0, but you have numpy 1.14.6 which is incompatible.\n",
            "pyerfa 2.0.0.1 requires numpy>=1.17, but you have numpy 1.14.6 which is incompatible.\n",
            "pyarrow 9.0.0 requires numpy>=1.16.6, but you have numpy 1.14.6 which is incompatible.\n",
            "prophet 1.1.1 requires numpy>=1.15.4, but you have numpy 1.14.6 which is incompatible.\n",
            "plotnine 0.8.0 requires numpy>=1.19.0, but you have numpy 1.14.6 which is incompatible.\n",
            "pandas 1.3.5 requires numpy>=1.17.3; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\", but you have numpy 1.14.6 which is incompatible.\n",
            "pandas-gbq 0.17.9 requires numpy>=1.16.6, but you have numpy 1.14.6 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.14.6 which is incompatible.\n",
            "mxnet-cu102 1.9.1 requires numpy<2.0.0,>1.16.0, but you have numpy 1.14.6 which is incompatible.\n",
            "librosa 0.8.1 requires numpy>=1.15.0, but you have numpy 1.14.6 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.14.6 which is incompatible.\n",
            "jaxlib 0.3.25+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.14.6 which is incompatible.\n",
            "jax 0.3.25 requires numpy>=1.20, but you have numpy 1.14.6 which is incompatible.\n",
            "imgaug 0.4.0 requires numpy>=1.15, but you have numpy 1.14.6 which is incompatible.\n",
            "httpstan 4.6.1 requires numpy<2.0,>=1.16, but you have numpy 1.14.6 which is incompatible.\n",
            "gym 0.25.2 requires numpy>=1.18.0, but you have numpy 1.14.6 which is incompatible.\n",
            "db-dtypes 1.0.4 requires numpy<2.0dev,>=1.16.6, but you have numpy 1.14.6 which is incompatible.\n",
            "cvxpy 1.2.2 requires numpy>=1.15, but you have numpy 1.14.6 which is incompatible.\n",
            "cmdstanpy 1.0.8 requires numpy>=1.21, but you have numpy 1.14.6 which is incompatible.\n",
            "blis 0.7.9 requires numpy>=1.15.0, but you have numpy 1.14.6 which is incompatible.\n",
            "astropy 4.3.1 requires numpy>=1.17, but you have numpy 1.14.6 which is incompatible.\n",
            "aesara 2.7.9 requires numpy>=1.17.0, but you have numpy 1.14.6 which is incompatible.\n",
            "aeppl 0.0.33 requires numpy>=1.18.1, but you have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "Successfully installed bert-embedding-1.0.1 gluonnlp-0.6.0 mxnet-1.4.0 numpy-1.14.6 typing-3.6.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "typing"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBbQwlK9gtsD"
      },
      "source": [
        "import mxnet as mx\n",
        "from bert_embedding import BertEmbedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa3Lb7LfhBCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66d6c9d6-c4ea-4935-8865-b3fedaed7bb4"
      },
      "source": [
        "# ctx = mx.gpu(0)\n",
        "bert = BertEmbedding()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab file is not found. Downloading.\n",
            "Downloading /root/.mxnet/models/book_corpus_wiki_en_uncased-a6607397.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/vocab/book_corpus_wiki_en_uncased-a6607397.zip...\n",
            "Downloading /root/.mxnet/models/bert_12_768_12_book_corpus_wiki_en_uncased-75cc780f.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/bert_12_768_12_book_corpus_wiki_en_uncased-75cc780f.zip...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxAdRCkFmq5R"
      },
      "source": [
        "from tqdm.auto import tqdm, trange"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrH9e6AIhXy5"
      },
      "source": [
        "bert_abstract = \"\"\"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers.\n",
        " Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations by jointly conditioning on both left and right context in all layers.\n",
        " As a result, the pre-trained BERT representations can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. \n",
        "BERT is conceptually simple and empirically powerful. \n",
        "It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE benchmark to 80.4% (7.6% absolute improvement), MultiNLI accuracy to 86.7 (5.6% absolute improvement) and the SQuAD v1.1 question answering Test F1 to 93.2 (1.5% absolute improvement), outperforming human performance by 2.0%.\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HM0FmfpphZP6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1de8315-ad0f-4048-a8e8-a38baba0b411"
      },
      "source": [
        "sentences = bert_abstract.split('\\n')\n",
        "result = bert(sentences)\n",
        "toks, embs = result[0]\n",
        "print(toks)\n",
        "print(len(toks), len(embs))\n",
        "print(embs[0][:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['we', 'introduce', 'a', 'new', 'language', 'representation', 'model', 'called', 'bert', ',', 'which', 'stands', 'for', 'bidirectional', 'encoder', 'representations', 'from', 'transformers']\n",
            "18 18\n",
            "[ 0.47964773  0.1824888  -0.28597528 -0.46567446  0.01248981 -0.07430505\n",
            " -0.18017295  0.37813222  0.9135139  -0.25295883]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR-AMiRKoxOP"
      },
      "source": [
        "# process a corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_hJoYtvmZw2"
      },
      "source": [
        "We download a 10k web-public .com corpus from https://wortschatz.uni-leipzig.de/en/download/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d_fuzIOngqC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10c4d56d-93fe-42f8-8f82-eadc0c1c1e11"
      },
      "source": [
        "!wget https://files.pushshift.io/gab/GABPOSTS_2018-10.xz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-27 04:12:55--  https://files.pushshift.io/gab/GABPOSTS_2018-10.xz\n",
            "Resolving files.pushshift.io (files.pushshift.io)... 104.21.28.11, 172.67.170.36, 2606:4700:3030::ac43:aa24, ...\n",
            "Connecting to files.pushshift.io (files.pushshift.io)|104.21.28.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 337144496 (322M) [application/octet-stream]\n",
            "Saving to: ‘GABPOSTS_2018-10.xz’\n",
            "\n",
            "GABPOSTS_2018-10.xz 100%[===================>] 321.53M  17.3MB/s    in 20s     \n",
            "\n",
            "2022-11-27 04:13:15 (16.4 MB/s) - ‘GABPOSTS_2018-10.xz’ saved [337144496/337144496]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zashEvfGnnnK"
      },
      "source": [
        "import lzma\n",
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "gab_posts = pd.DataFrame()\n",
        "temp = []\n",
        "counter = 0\n",
        "with lzma.open('GABPOSTS_2018-10.xz', mode='r') as file:\n",
        "    for line in file:\n",
        "      # Can add raw/other fields, just worried about memory requirements\n",
        "      # I think I did this in a cleaner way before, but w/e it works :)\n",
        "      if counter > 36000:\n",
        "        break\n",
        "      counter = counter + 1\n",
        "      temp.append({\"body\": re.sub(r\"(?:\\@|\\\\|https?\\://)\\S+\", \"\",json.loads(line)['body']), \"date\":json.loads(line)['created_at']})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCWGTugrocOZ"
      },
      "source": [
        "gab_posts = gab_posts.append(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(temp)"
      ],
      "metadata": {
        "id": "CFMT77_f8hUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "banned_words = ['pussie', 'phonesex', 'footjob', 'horniest', 'clitoris', 'headfuck', 'areola', 'pussies', 'goddamnes', 'suicide', 'voyeurweb', 'suicide girls', 'niggarded', 'deepthroat', 'fuckbuddy', 'nigra', 'freefuck', 'boob', 'hentai', 'rentafuck', 'wanking', 'jerk off', 'molester', 'horney', 'titfuckin', 'milf', 'wrapping men', 'whorefucker', 'masturbating', 'dick', 'honkers', 'chocolate rosebuds', 'neonazi', 'vibrater', 'uptheass', 'shitdick', 'pussycat', 'naked', 'group sex', 'suckmydick', 'pussyeater', 'masturbate', 'stupidfuck', 'nig', 'rape', 'meth', 'virgin', 'livesex', 'terrorist', 'upskirt', 'shortfuck', 'genital', 'jiggaboo', 'marijuana', 'cumshots', 'koon', 'holestuffer', 'tit', 'assbagger', 'ball sack', 'sexpot', 'suckmyass', 'lovejuice', 'phukking', 'wigger', 'black cock', 'whiskeydick', 'blonde on blonde action', 'retarded', 'kunt', 'motherfuckin', 'orgy', 'ejaculation', 'fuckme', 'phone sex', 'fuckher', 'niggerhole', 'intercourse', 'pussylips', 'niggardly', 'tongethruster', 'nig nog', 'kumbullbe', 'nigger', 'wanker', 'peepshpw', 'cocks', 'omorashi', 'female squirting', 'blow job', 'bung hole', 'homicide', 'penetration', 'puddboy', 'gang bang', 'lickme', 'spermhearder', 'titties', 'rigger', 'shitblimp', 'twat', 'fag', 'gangbanger', 'orgasim', 'porno', 'assfuck', 'pussy', 'sodomy', 'cumshot', 'cock', 'jihad', 'niggaz', 'picaninny', 'bondage', 'dry hump', 'poorwhitetrash', 'whitenigger', 'nip', 'masturbation', 'peni5', 'sexed', 'escort', 'g-spot', 'muffindiver', 'fingerbang', 'shite', 'gypo', 'scrotum', 'creampie', 'goddamnmuthafucker', 'foreskin', 'titty', 'dildo', 'sexkitten', 'anus', 'niggling', 'niggerhead', 'footlicker', 'pussylover', 'limpdick', 'fucktard', 'male squirting', 'gangbang', 'nigg', 'suckdick', 'vagina', 'reestie', 'bangbros', 'givehead', 'spank', 'trailertrash', 'giant cock', 'fucktards', 'sexo', 'pussypounder', 'gaymuthafuckinwhore', 'negroid', 'lsd', 'ball gag', 'jigga', \"nigger's\", 'orgasm', 'nlgger', 'asskiss', 'coprolagnia', 'boobs', 'pussylicker', 'whitetrash', 'mothafuckings', 'fingering', 'scum', 'paedophile', 'sperm', 'testicle', 'poopchute', 'wank', 'jerkoff', 'octopussy', 'pedophile', 'reverse cowgirl', 'negroes', 'suckmytit', 'big tits', 'sonofbitch', 'swastika', 'jizz', 'sexslave', 'bunghole', 'retard', 'hore', 'nipplering', 'kink', 'nipples', 'vaginal', 'tittie', 'hitler', 'jiggabo', 'pedobear', 'handjob', 'pubic', 'kkk', 'niggled', 'pthc', \"negro's\", 'doggystyle', 'samckdaddy', 'gangbanged', 'clit', 'hand job', 'beaners', 'ecchi', 'doggy style', 'nutten', 'bdsm', 'cunnilingus', 'killing', 'genitals', 'poop chute', 'fuckfest', 'spermherder', 'brunette action', 'motherfuck', 'cumming', 'erotic', 'splooge moose', 'foursome', 'niglet', 'nigre', 'incest', 'cunt', 'molest', 'threesome', 'kissass', 'narcotic', 'sexhouse', 'nudity', 'fudgepacker', 'snownigger', 'white power', 'jiggerboo', 'honky', 'rosy palm and her 5 sisters', 'nittit', 'horny', 'hotpussy', 'ball sucking', 'nignog', 'palesimian', 'jizjuice', 'zoophilia', 'nigga', 'asslicker', 'niggle', 'nlggor', 'pornography', 'sexing', 'slutt', 'titlicker', 'kunnilingus', 'fuckwhore', 'wet dream', 'spunk', 'pisser', 'puss', 'boner', 'skeet', 'sextoys', 'vibrator', 'manpaste', 'faggot', 'humping', 'nipple', 'double penetration', 'coons', 'assklown', 'pubes', 'fuckface', 'anal', 'nimphomania', 'blowjob', 'rimjob', 'fisting', 'niggardliness', 'sultry women', 'jizzim', 'kinkster', 'skankfuck', 'penis', 'how to kill', 'semen', 'mothafucker', 'analsex', 'niggur', 'panty', 'deep throat', 'foot fetish', 'freakyfucker', 'date rape', 'assblaster', 'bukkake', 'lesbo', 'spaghettinigger', 'beaner', 'clover clamps', 'twobitwhore', 'nigr', 'fuckfriend', 'sextoy', 'prostitute', 'pussyfucker', 'kanake', 'porchmonkey', 'testicles', 'erotism', 'pusy', 'assjockey', 'pimpjuic', 'booty call', 'kaffir', 'fuckable', 'goldenshower', 'homobangers', 'pegging', 'rapist', 'venus mound', 'raping', 'fudge packer', 'sexcam', 'timbernigger', 'viagra', 'make me come', 'beastiality', 'leather restraint', 'coon', 'futanari', 'fuckina', 'iblowu', 'masterbate', 'luckycammeltoe', \"niggardliness's\", 'fuckmehard', 'tits', 'suckme', 'intheass', 'niggarding', 'tonguetramp', 'niggor', 'schlong', 'niggah', 'raped', 'nazi', 'two girls one cup', 'huge fat', 'upthebutt', 'daterape', 'mastabater', 'cum', 'asslick', 'raghead', 'bestiality', 'golden shower', 'niggers', 'penises', 'mufflikcer', 'camel toe', 'shaved pussy', 'niggles', 'jijjiboo']\n"
      ],
      "metadata": {
        "id": "kofx-oobsKB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "gab_posts['body'].replace(r'\\n',' ', regex=True, inplace=True)\n",
        "gab_posts['body'].replace(r'\\r',' ', regex=True, inplace=True)\n",
        "gab_posts['body'].replace('', np.nan, inplace=True)\n",
        "gab_posts.dropna(subset=['body'], inplace=True)\n",
        "gab_posts['body'].str.lower()\n"
      ],
      "metadata": {
        "id": "LLVWcfdwsOxt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4314e82-ddfc-4883-ca04-6fa43bc61a98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                       #trade #winning   \n",
              "1        o deputado arthur lira (pp/al):  ⚠️ responde a...\n",
              "2                      cocaine mitch comes out swinging.  \n",
              "3        #demoncrats have no redeeming value. a black c...\n",
              "4        putting up the rent in one town/city/country w...\n",
              "                               ...                        \n",
              "35996    wow, you have some pent up anger it seems. don...\n",
              "35997                     see ya , wouldn't want to be ya.\n",
              "35998           wieder hat die antifa rassisten entlarvt. \n",
              "35999         is she /he one of those transgender mutants?\n",
              "36000                  the normies they make vader afraid.\n",
              "Name: body, Length: 31807, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QghFckJrumO"
      },
      "source": [
        "remove row index from each sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7FTLEtgrlGE"
      },
      "source": [
        "all_sentences = gab_posts['body'].to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOLT6c7yotcW"
      },
      "source": [
        "# create a search index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZvELpMSsyer"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7MAHVbbsz3t"
      },
      "source": [
        "from sklearn.neighbors import KDTree\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class ContextNeighborStorage:\n",
        "    def __init__(self, sentences, model):\n",
        "        self.sentences = sentences\n",
        "        self.model = model\n",
        "\n",
        "    def process_sentences(self):\n",
        "        result = self.model(self.sentences)\n",
        "\n",
        "        self.sentence_ids = []\n",
        "        self.token_ids = []\n",
        "        self.all_tokens = []\n",
        "        all_embeddings = []\n",
        "        for i, (toks, embs) in enumerate(tqdm(result)):\n",
        "            for j, (tok, emb) in enumerate(zip(toks, embs)):\n",
        "                self.sentence_ids.append(i)\n",
        "                self.token_ids.append(j)\n",
        "                self.all_tokens.append(tok)\n",
        "                all_embeddings.append(emb)\n",
        "        all_embeddings = np.stack(all_embeddings)\n",
        "        # we normalize embeddings, so that euclidian distance is equivalent to cosine distance\n",
        "        self.normed_embeddings = (all_embeddings.T / (all_embeddings**2).sum(axis=1) ** 0.5).T\n",
        "\n",
        "    def build_search_index(self):\n",
        "        # this takes some time\n",
        "        self.indexer = KDTree(self.normed_embeddings)\n",
        "\n",
        "    def query(self, query_sent, query_word, k=10, filter_same_word=False):\n",
        "        toks, embs = self.model([query_sent])[0]\n",
        "\n",
        "        found = False\n",
        "        for tok, emb in zip(toks, embs):\n",
        "            if tok == query_word:\n",
        "                found = True\n",
        "                break\n",
        "        if not found:\n",
        "            raise ValueError('The query word {} is not a single token in sentence {}'.format(query_word, toks))\n",
        "        emb = emb / sum(emb**2)**0.5\n",
        "\n",
        "        if filter_same_word:\n",
        "            initial_k = max(k, 100)\n",
        "        else:\n",
        "            initial_k = k\n",
        "        di, idx = self.indexer.query(emb.reshape(1, -1), k=initial_k)\n",
        "        distances = []\n",
        "        neighbors = []\n",
        "        contexts = []\n",
        "        for i, index in enumerate(idx.ravel()):\n",
        "            token = self.all_tokens[index]\n",
        "            if filter_same_word and (query_word in token or token in query_word):\n",
        "                continue\n",
        "            distances.append(di.ravel()[i])\n",
        "            neighbors.append(token)\n",
        "            contexts.append(self.sentences[self.sentence_ids[index]])\n",
        "            if len(distances) == k:\n",
        "                break\n",
        "        return distances, neighbors, contexts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIiBCBOauY6J"
      },
      "source": [
        "Now let's use this indexer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rB5NoR7AqJ6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "258ae576ba564c0fa4bf87babcf639fc",
            "e583ef4f9a7e4998ac5a81248b7f242d",
            "be4734c6794940bdb4d7e93f1605a55d",
            "30735375d6b8446a9ec54e8c395d4d9e",
            "ff65fb5f92124810a804e7a2f0e7a109",
            "423af480d48d44b68fba49d62382b1ab",
            "21f1e9c96d9e46e59acde11a7a3a107e",
            "32399539c586489aa51a0759391dc706",
            "e7704fde6d2240968891f07bad597042",
            "e35d7c763c0742fd8051478245dcebac",
            "fbaf18e597a14d1cb52cfdcb30913369"
          ]
        },
        "outputId": "ed4f1c57-e832-4189-98ba-c97ffee22fd2"
      },
      "source": [
        "storage = ContextNeighborStorage(sentences=all_sentences, model=bert)\n",
        "storage.process_sentences()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/31807 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "258ae576ba564c0fa4bf87babcf639fc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_sEJcvtzPs5"
      },
      "source": [
        "Creating the index would require some time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWcGzTNxuJm9"
      },
      "source": [
        "storage.build_search_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "banned_sentences = dict((word,[]) for word in banned_words)\n",
        "\n",
        "\n",
        "for idx, entry in gab_posts.iterrows():\n",
        "  body = entry['body']\n",
        "  for word in banned_words:\n",
        "    if word in body:\n",
        "      # Can just include sentence if we want\n",
        "      banned_sentences[word].append(body)"
      ],
      "metadata": {
        "id": "eBWJH5W0Sf38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_count = {}\n",
        "for banned_word, sentences in banned_sentences.items():\n",
        "  ctr_passed_sentences = 0\n",
        "  ctr_total_checked = 0\n",
        "  final_count[banned_word] = {}\n",
        "  for sentence in sentences:\n",
        "    if ctr_passed_sentences > 100 or ctr_total_checked > 1000:\n",
        "      break\n",
        "    ctr_total_checked = ctr_total_checked + 1\n",
        "    try:\n",
        "      distances, neighbors, contexts = storage.query(query_sent=sentence, query_word=banned_word, k=5, filter_same_word=True)\n",
        "      # print('BANNED WORD: {} \\n ORIGINAL SENTENCE: {} '.format(banned_word, sentence))\n",
        "      for w in neighbors:\n",
        "          if w in final_count[banned_word]:\n",
        "            final_count[banned_word][w] = final_count[banned_word][w] + 1\n",
        "          else:\n",
        "            final_count[banned_word][w] = 1\n",
        "      # for d, w, c in zip(distances, neighbors, contexts):\n",
        "      ctr_passed_sentences = ctr_passed_sentences + 1\n",
        "          # print('{} {}  {}'.format(w, d, c.strip()))\n",
        "    except Exception as e:\n",
        "      continue"
      ],
      "metadata": {
        "id": "naPQ_LhmmnSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finalized_top_10 = {}\n",
        "\n",
        "for key, occur_dict in final_count.items():\n",
        "  if len(occur_dict.keys()) > 0:\n",
        "    # Sort occurances\n",
        "    sorted_dict = dict(sorted(occur_dict.items(), key=lambda item: item[1], reverse=True))\n",
        "    # Take top 10\n",
        "    finalized_top_10[key] = {k: sorted_dict[k] for k in list(sorted_dict)[:10]}\n",
        "  else:\n",
        "    finalized_top_10[key] = {}"
      ],
      "metadata": {
        "id": "uXoBMEZtKn2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finalized_top_10\n",
        "import json\n",
        "with open('top_10_36000.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(finalized_top_10, f, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "id": "co-aLK-FMHFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finalized_top_10\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zm93BjoqNlPF",
        "outputId": "5385cbf2-b291-49a0-b91b-fd79fb4d9913"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pussie': {},\n",
              " 'phonesex': {},\n",
              " 'footjob': {},\n",
              " 'horniest': {},\n",
              " 'clitoris': {},\n",
              " 'headfuck': {},\n",
              " 'areola': {},\n",
              " 'pussies': {'faggot': 3,\n",
              "  'fags': 2,\n",
              "  'titties': 1,\n",
              "  'wussies': 1,\n",
              "  'buttercups': 1,\n",
              "  'pukes': 1,\n",
              "  'perverts': 1},\n",
              " 'goddamnes': {},\n",
              " 'suicide': {'death': 11,\n",
              "  'murder': 11,\n",
              "  'die': 10,\n",
              "  'rape': 9,\n",
              "  'committing': 6,\n",
              "  'treason': 5,\n",
              "  'suicidal': 3,\n",
              "  'commit': 2,\n",
              "  'jihadis': 2,\n",
              "  'committed': 2},\n",
              " 'voyeurweb': {},\n",
              " 'suicide girls': {},\n",
              " 'niggarded': {},\n",
              " 'deepthroat': {},\n",
              " 'fuckbuddy': {},\n",
              " 'nigra': {},\n",
              " 'freefuck': {},\n",
              " 'boob': {'blowjob': 2, 'booger': 1, 'boop': 1, 'douche': 1},\n",
              " 'hentai': {'futanari': 4,\n",
              "  'futa': 4,\n",
              "  'bisokuzenshin': 4,\n",
              "  'kasumi': 3,\n",
              "  'ecchi': 2,\n",
              "  'hirono': 1,\n",
              "  'yori': 1,\n",
              "  'arigato': 1},\n",
              " 'rentafuck': {},\n",
              " 'wanking': {},\n",
              " 'jerk off': {},\n",
              " 'molester': {'rapist': 4,\n",
              "  'molestors': 3,\n",
              "  'molested': 1,\n",
              "  'molestation': 1,\n",
              "  'molesting': 1},\n",
              " 'horney': {},\n",
              " 'titfuckin': {},\n",
              " 'milf': {},\n",
              " 'wrapping men': {},\n",
              " 'whorefucker': {},\n",
              " 'masturbating': {},\n",
              " 'dick': {'penis': 47,\n",
              "  'cock': 21,\n",
              "  'shit': 7,\n",
              "  'ass': 5,\n",
              "  'of': 4,\n",
              "  'asshole': 3,\n",
              "  'cunt': 2,\n",
              "  'a': 2,\n",
              "  'death': 2,\n",
              "  'sucking': 2},\n",
              " 'honkers': {},\n",
              " 'chocolate rosebuds': {},\n",
              " 'neonazi': {},\n",
              " 'vibrater': {},\n",
              " 'uptheass': {},\n",
              " 'shitdick': {},\n",
              " 'pussycat': {},\n",
              " 'naked': {'nude': 3,\n",
              "  'genitals': 2,\n",
              "  'rape': 2,\n",
              "  'with': 2,\n",
              "  'her': 2,\n",
              "  'virgin': 1,\n",
              "  'spanked': 1,\n",
              "  'pantys': 1,\n",
              "  'clothes': 1,\n",
              "  'nudes': 1},\n",
              " 'group sex': {},\n",
              " 'suckmydick': {},\n",
              " 'pussyeater': {},\n",
              " 'masturbate': {'promiscuity': 3, 'masturbation': 1, 'genitals': 1},\n",
              " 'stupidfuck': {},\n",
              " 'nig': {},\n",
              " 'rape': {'assault': 146,\n",
              "  'raping': 44,\n",
              "  'sexual': 43,\n",
              "  'sex': 38,\n",
              "  'abuse': 12,\n",
              "  'murder': 10,\n",
              "  'gang': 9,\n",
              "  'fuck': 8,\n",
              "  'beat': 7,\n",
              "  'molestation': 4},\n",
              " 'meth': {'fentanyl': 2,\n",
              "  'opioid': 1,\n",
              "  'opioids': 1,\n",
              "  'ingest': 1,\n",
              "  'lsd': 1,\n",
              "  'psychotropic': 1,\n",
              "  'drug': 1,\n",
              "  'collagen': 1,\n",
              "  'pedophiles': 1},\n",
              " 'virgin': {'prostitute': 3,\n",
              "  'christ': 3,\n",
              "  'female': 2,\n",
              "  'a': 2,\n",
              "  'sex': 2,\n",
              "  'pagan': 2,\n",
              "  'christian': 2,\n",
              "  'penis': 2,\n",
              "  'pauly': 1,\n",
              "  'girlfriend': 1},\n",
              " 'livesex': {},\n",
              " 'terrorist': {'terrorism': 37,\n",
              "  'militants': 3,\n",
              "  'fbi': 2,\n",
              "  'isis': 2,\n",
              "  'muslim': 2,\n",
              "  'leftist': 2,\n",
              "  'criminal': 1,\n",
              "  'scientist': 1,\n",
              "  'domestic': 1,\n",
              "  'wing': 1},\n",
              " 'upskirt': {},\n",
              " 'shortfuck': {},\n",
              " 'genital': {'mutilation': 6,\n",
              "  'female': 2,\n",
              "  'infant': 2,\n",
              "  'sexually': 1,\n",
              "  'male': 1,\n",
              "  'circumcision': 1,\n",
              "  'mutila': 1,\n",
              "  'menstrual': 1},\n",
              " 'jiggaboo': {},\n",
              " 'marijuana': {'weed': 2, 'cannabis': 1, 'heroin': 1, 'drugs': 1},\n",
              " 'cumshots': {},\n",
              " 'koon': {},\n",
              " 'holestuffer': {},\n",
              " 'tit': {'larping': 1, 'the': 1, 'nigglets': 1, 'snit': 1, 'dipshit': 1},\n",
              " 'assbagger': {},\n",
              " 'ball sack': {},\n",
              " 'sexpot': {},\n",
              " 'suckmyass': {},\n",
              " 'lovejuice': {},\n",
              " 'phukking': {},\n",
              " 'wigger': {},\n",
              " 'black cock': {},\n",
              " 'whiskeydick': {},\n",
              " 'blonde on blonde action': {},\n",
              " 'retarded': {'retards': 61,\n",
              "  'retardation': 4,\n",
              "  'degenerate': 2,\n",
              "  'autistic': 2,\n",
              "  'deranged': 2,\n",
              "  'senile': 2,\n",
              "  'too': 1,\n",
              "  'crippled': 1,\n",
              "  'firmed': 1,\n",
              "  'hypocrites': 1},\n",
              " 'kunt': {},\n",
              " 'motherfuckin': {},\n",
              " 'orgy': {'satanic': 1,\n",
              "  'sex': 1,\n",
              "  'tranny': 1,\n",
              "  'cannibalism': 1,\n",
              "  'rapefugee': 1,\n",
              "  'outcry': 1,\n",
              "  'group': 1,\n",
              "  'campaigner': 1,\n",
              "  'to': 1,\n",
              "  'wannacry': 1},\n",
              " 'ejaculation': {},\n",
              " 'fuckme': {},\n",
              " 'phone sex': {},\n",
              " 'fuckher': {},\n",
              " 'niggerhole': {},\n",
              " 'intercourse': {},\n",
              " 'pussylips': {},\n",
              " 'niggardly': {},\n",
              " 'tongethruster': {},\n",
              " 'nig nog': {},\n",
              " 'kumbullbe': {},\n",
              " 'nigger': {'nigga': 35,\n",
              "  'niggas': 13,\n",
              "  'white': 12,\n",
              "  'faggot': 10,\n",
              "  'chinks': 9,\n",
              "  'crone': 8,\n",
              "  'chimps': 5,\n",
              "  'klanner': 4,\n",
              "  'faggots': 2,\n",
              "  'racists': 2},\n",
              " 'wanker': {},\n",
              " 'peepshpw': {},\n",
              " 'cocks': {},\n",
              " 'omorashi': {},\n",
              " 'female squirting': {},\n",
              " 'blow job': {},\n",
              " 'bung hole': {},\n",
              " 'homicide': {'police': 3,\n",
              "  'murder': 3,\n",
              "  'detective': 1,\n",
              "  'cop': 1,\n",
              "  'negligent': 1,\n",
              "  'prosecuter': 1},\n",
              " 'penetration': {},\n",
              " 'puddboy': {},\n",
              " 'gang bang': {},\n",
              " 'lickme': {},\n",
              " 'spermhearder': {},\n",
              " 'titties': {'nigglets': 2,\n",
              "  'pussies': 2,\n",
              "  'petticoat': 1,\n",
              "  'shitskins': 1,\n",
              "  'pantys': 1,\n",
              "  'swastika': 1,\n",
              "  'snit': 1,\n",
              "  'buttercups': 1},\n",
              " 'rigger': {},\n",
              " 'shitblimp': {},\n",
              " 'twat': {'twit': 6,\n",
              "  'gab': 1,\n",
              "  'cunt': 1,\n",
              "  'gimp': 1,\n",
              "  'strawman': 1,\n",
              "  'trumpanzees': 1,\n",
              "  'timetowakeup': 1,\n",
              "  'nigglets': 1,\n",
              "  'twittr': 1,\n",
              "  'dumfuck': 1},\n",
              " 'fag': {'fam': 8,\n",
              "  'skank': 7,\n",
              "  'scumbag': 5,\n",
              "  'pedo': 3,\n",
              "  'hag': 3,\n",
              "  'slutbot': 2,\n",
              "  'gger': 2,\n",
              "  'retard': 2,\n",
              "  'slob': 2,\n",
              "  'gabbers': 2},\n",
              " 'gangbanger': {},\n",
              " 'orgasim': {},\n",
              " 'porno': {'pornstar': 9,\n",
              "  'movie': 1,\n",
              "  'a': 1,\n",
              "  'interracial': 1,\n",
              "  'orgy': 1,\n",
              "  'erotica': 1,\n",
              "  'pornbot': 1},\n",
              " 'assfuck': {},\n",
              " 'pussy': {'penis': 8,\n",
              "  'cunt': 7,\n",
              "  'dick': 6,\n",
              "  'shit': 5,\n",
              "  'ass': 4,\n",
              "  'tits': 3,\n",
              "  'fuck': 3,\n",
              "  'cock': 3,\n",
              "  'whore': 3,\n",
              "  'sexual': 3},\n",
              " 'sodomy': {'sodomite': 6, 'sodomize': 2, 'sodomites': 2},\n",
              " 'cumshot': {'kancolle': 1,\n",
              "  'tsunday': 1,\n",
              "  'pokin': 1,\n",
              "  'rotflmao': 1,\n",
              "  'bolsonaropsdb': 1},\n",
              " 'cock': {'penis': 16,\n",
              "  'dick': 16,\n",
              "  'pig': 4,\n",
              "  'poppy': 2,\n",
              "  'chicken': 2,\n",
              "  'pussy': 2,\n",
              "  'piss': 1,\n",
              "  'spewing': 1,\n",
              "  'dickcam': 1,\n",
              "  'sausage': 1},\n",
              " 'jihad': {'islamic': 2, 'muslimes': 1, 'muslim': 1, 'islam': 1},\n",
              " 'niggaz': {},\n",
              " 'picaninny': {},\n",
              " 'bondage': {},\n",
              " 'dry hump': {},\n",
              " 'poorwhitetrash': {},\n",
              " 'whitenigger': {},\n",
              " 'nip': {},\n",
              " 'masturbation': {'promiscuity': 2,\n",
              "  'masturbate': 1,\n",
              "  'sex': 1,\n",
              "  'sexualharassment': 1},\n",
              " 'peni5': {},\n",
              " 'sexed': {},\n",
              " 'escort': {'service': 1, 'womanizer': 1, 'sexual': 1, 'dating': 1, 'drag': 1},\n",
              " 'g-spot': {},\n",
              " 'muffindiver': {},\n",
              " 'fingerbang': {},\n",
              " 'shite': {'shitbird': 5,\n",
              "  'libtards': 4,\n",
              "  'shitlib': 4,\n",
              "  'shitskin': 3,\n",
              "  'shitlibs': 3,\n",
              "  'shitbirds': 3,\n",
              "  'like': 2,\n",
              "  'haterz': 2,\n",
              "  'tripe': 1,\n",
              "  'shitholeans': 1},\n",
              " 'gypo': {},\n",
              " 'scrotum': {},\n",
              " 'creampie': {},\n",
              " 'goddamnmuthafucker': {},\n",
              " 'foreskin': {'shitskins': 2,\n",
              "  'their': 2,\n",
              "  'sew': 2,\n",
              "  'penis': 2,\n",
              "  'floppy': 1,\n",
              "  'hambones': 1,\n",
              "  'off': 1,\n",
              "  'they': 1,\n",
              "  'testicle': 1,\n",
              "  'a': 1},\n",
              " 'titty': {'twatter': 2,\n",
              "  'libtards': 2,\n",
              "  'twittr': 2,\n",
              "  'libturd': 1,\n",
              "  'whiny': 1,\n",
              "  'trumb': 1,\n",
              "  'niec': 1},\n",
              " 'dildo': {'pedo': 3, 'lolol': 1, 'cuckadoodledo': 1},\n",
              " 'sexkitten': {},\n",
              " 'anus': {'genitals': 2,\n",
              "  'panty': 1,\n",
              "  'vaginas': 1,\n",
              "  'pubes': 1,\n",
              "  'suceed': 1,\n",
              "  'vagisil': 1,\n",
              "  'tds': 1,\n",
              "  'sesspool': 1,\n",
              "  'turd': 1},\n",
              " 'niggling': {},\n",
              " 'niggerhead': {},\n",
              " 'footlicker': {},\n",
              " 'pussylover': {},\n",
              " 'limpdick': {},\n",
              " 'fucktard': {'retard': 10,\n",
              "  'shill': 1,\n",
              "  'fuckwit': 1,\n",
              "  'nutflix': 1,\n",
              "  'dumbfuck': 1,\n",
              "  'motherfucker': 1},\n",
              " 'male squirting': {},\n",
              " 'gangbang': {},\n",
              " 'nigg': {},\n",
              " 'suckdick': {},\n",
              " 'vagina': {'penis': 3, 'penises': 1, 'sexually': 1},\n",
              " 'reestie': {},\n",
              " 'bangbros': {},\n",
              " 'givehead': {},\n",
              " 'spank': {},\n",
              " 'trailertrash': {},\n",
              " 'giant cock': {},\n",
              " 'fucktards': {'fuckers': 2, 'fuckwit': 1, 'shitheads': 1, '-': 1},\n",
              " 'sexo': {'animais': 1, 'medo': 1, 'fez': 1, 'lixo': 1, 'foi': 1},\n",
              " 'pussypounder': {},\n",
              " 'gaymuthafuckinwhore': {},\n",
              " 'negroid': {},\n",
              " 'lsd': {},\n",
              " 'ball gag': {},\n",
              " 'jigga': {},\n",
              " \"nigger's\": {},\n",
              " 'orgasm': {'sex': 2, 'sexually': 1, 'boner': 1, 'vagina': 1},\n",
              " 'nlgger': {},\n",
              " 'asskiss': {},\n",
              " 'coprolagnia': {},\n",
              " 'boobs': {'boogers': 4,\n",
              "  'tits': 3,\n",
              "  'booger': 2,\n",
              "  'penises': 2,\n",
              "  'pantys': 2,\n",
              "  'masculinity': 2,\n",
              "  'fags': 1,\n",
              "  'unhealthy': 1,\n",
              "  'pussy': 1,\n",
              "  'genitals': 1},\n",
              " 'pussylicker': {},\n",
              " 'whitetrash': {},\n",
              " 'mothafuckings': {},\n",
              " 'fingering': {'raping': 1,\n",
              "  'trashing': 1,\n",
              "  'shitting': 1,\n",
              "  'sucking': 1,\n",
              "  'shaming': 1,\n",
              "  'girlplay': 1,\n",
              "  'lesbians': 1,\n",
              "  'shitposting': 1,\n",
              "  'womensfashion': 1,\n",
              "  'nsfw': 1},\n",
              " 'scum': {'filth': 16,\n",
              "  'slut': 9,\n",
              "  'schmuck': 7,\n",
              "  'schmucks': 7,\n",
              "  'dope': 6,\n",
              "  'fucker': 5,\n",
              "  'hypocrisy': 4,\n",
              "  'morons': 3,\n",
              "  'shit': 3,\n",
              "  'subversive': 3},\n",
              " 'paedophile': {'pedophile': 7, 'pedophiles': 3},\n",
              " 'sperm': {'egg': 2, 'wombs': 1, 'fetuses': 1, 'baby': 1},\n",
              " 'testicle': {'skin': 1,\n",
              "  'scrotal': 1,\n",
              "  'genitalia': 1,\n",
              "  'penis': 1,\n",
              "  'growth': 1,\n",
              "  'genitals': 1,\n",
              "  'panty': 1,\n",
              "  'knickers': 1,\n",
              "  'anus': 1,\n",
              "  'foreskin': 1},\n",
              " 'poopchute': {},\n",
              " 'wank': {},\n",
              " 'jerkoff': {},\n",
              " 'octopussy': {},\n",
              " 'pedophile': {'pedophilia': 76,\n",
              "  'paedophile': 9,\n",
              "  'pedowood': 3,\n",
              "  'pedopope': 1,\n",
              "  'paedophiles': 1},\n",
              " 'reverse cowgirl': {},\n",
              " 'negroes': {'negros': 7, 'americans': 1, 'shitlibs': 1, 'blacks': 1},\n",
              " 'suckmytit': {},\n",
              " 'big tits': {},\n",
              " 'sonofbitch': {},\n",
              " 'swastika': {'scumbag': 4,\n",
              "  'neo': 1,\n",
              "  'nazi': 1,\n",
              "  'moslim': 1,\n",
              "  'faggotry': 1,\n",
              "  'smear': 1,\n",
              "  'fedora': 1,\n",
              "  'scum': 1,\n",
              "  'mark': 1,\n",
              "  'symbol': 1},\n",
              " 'jizz': {'on': 1, 'unspeech': 1, 'larping': 1, 'upvote': 1, 'hoverhand': 1},\n",
              " 'sexslave': {},\n",
              " 'bunghole': {},\n",
              " 'retard': {'fucktard': 38,\n",
              "  'fucktards': 5,\n",
              "  'gabbers': 4,\n",
              "  'deranged': 4,\n",
              "  'hypocrite': 4,\n",
              "  'moron': 3,\n",
              "  'perverts': 3,\n",
              "  'faggot': 2,\n",
              "  'supremacist': 2,\n",
              "  'degenerate': 2},\n",
              " 'hore': {'shemale': 5},\n",
              " 'nipplering': {},\n",
              " 'kink': {},\n",
              " 'nipples': {'penises': 2, 'pierced': 1, 'tits': 1, 'breasts': 1},\n",
              " 'vaginal': {},\n",
              " 'tittie': {},\n",
              " 'hitler': {'nazi': 10,\n",
              "  'nazis': 5,\n",
              "  'stalin': 1,\n",
              "  'germany': 1,\n",
              "  'germans': 1,\n",
              "  'europe': 1,\n",
              "  'aryan': 1},\n",
              " 'jiggabo': {},\n",
              " 'pedobear': {},\n",
              " 'handjob': {},\n",
              " 'pubic': {},\n",
              " 'kkk': {'kkjkk': 8,\n",
              "  'pq': 8,\n",
              "  'kd': 5,\n",
              "  'kek': 3,\n",
              "  'fj': 2,\n",
              "  'kag': 1,\n",
              "  'ainda': 1,\n",
              "  'fhc': 1,\n",
              "  'stf': 1,\n",
              "  'dmtbka': 1},\n",
              " 'niggled': {},\n",
              " 'pthc': {},\n",
              " \"negro's\": {},\n",
              " 'doggystyle': {},\n",
              " 'samckdaddy': {},\n",
              " 'gangbanged': {},\n",
              " 'clit': {},\n",
              " 'hand job': {},\n",
              " 'beaners': {},\n",
              " 'ecchi': {'hentai': 3, 'futa': 1, 'difichi': 1},\n",
              " 'doggy style': {},\n",
              " 'nutten': {},\n",
              " 'bdsm': {},\n",
              " 'cunnilingus': {},\n",
              " 'killing': {'killed': 30,\n",
              "  'murdering': 22,\n",
              "  'destroying': 12,\n",
              "  'raping': 5,\n",
              "  'murder': 4,\n",
              "  'attacking': 3,\n",
              "  'murdered': 3,\n",
              "  'slaughtered': 2,\n",
              "  'eating': 2,\n",
              "  'losing': 2},\n",
              " 'genitals': {'penises': 4, 'pantys': 2, 'genitalia': 2, 'panty': 1, 'on': 1},\n",
              " 'poop chute': {},\n",
              " 'fuckfest': {},\n",
              " 'spermherder': {},\n",
              " 'brunette action': {},\n",
              " 'motherfuck': {},\n",
              " 'cumming': {},\n",
              " 'erotic': {},\n",
              " 'splooge moose': {},\n",
              " 'foursome': {},\n",
              " 'niglet': {},\n",
              " 'nigre': {},\n",
              " 'incest': {'adulterous': 3,\n",
              "  'unfaithful': 2,\n",
              "  'adultery': 2,\n",
              "  'suction': 1,\n",
              "  'molestation': 1,\n",
              "  'raping': 1,\n",
              "  'slut': 1,\n",
              "  'rapist': 1,\n",
              "  'muzzie': 1,\n",
              "  'sodomite': 1},\n",
              " 'cunt': {'slut': 28,\n",
              "  'skank': 26,\n",
              "  'wuss': 5,\n",
              "  'sodomite': 4,\n",
              "  'faggot': 4,\n",
              "  'bitch': 3,\n",
              "  'jackass': 3,\n",
              "  'cuck': 3,\n",
              "  'fucktard': 2,\n",
              "  'scumbag': 2},\n",
              " 'molest': {},\n",
              " 'threesome': {},\n",
              " 'kissass': {},\n",
              " 'narcotic': {},\n",
              " 'sexhouse': {},\n",
              " 'nudity': {},\n",
              " 'fudgepacker': {},\n",
              " 'snownigger': {},\n",
              " 'white power': {},\n",
              " 'jiggerboo': {},\n",
              " 'honky': {},\n",
              " 'rosy palm and her 5 sisters': {},\n",
              " 'nittit': {},\n",
              " 'horny': {'feminists': 2,\n",
              "  'masturbate': 1,\n",
              "  'skanked': 1,\n",
              "  'womanizer': 1,\n",
              "  'douche': 1,\n",
              "  'drunk': 1,\n",
              "  'harpy': 1,\n",
              "  'binge': 1,\n",
              "  'man': 1,\n",
              "  'drinking': 1},\n",
              " 'hotpussy': {},\n",
              " 'ball sucking': {},\n",
              " 'nignog': {},\n",
              " 'palesimian': {},\n",
              " 'jizjuice': {},\n",
              " 'zoophilia': {},\n",
              " 'nigga': {'nigger': 12,\n",
              "  'niggers': 3,\n",
              "  'nigs': 1,\n",
              "  'coote': 1,\n",
              "  'nigglets': 1,\n",
              "  'weeb': 1,\n",
              "  'nutflix': 1},\n",
              " 'asslicker': {},\n",
              " 'niggle': {},\n",
              " 'nlggor': {},\n",
              " 'pornography': {'rape': 7,\n",
              "  'censorship': 3,\n",
              "  'molestation': 2,\n",
              "  'pornbot': 1,\n",
              "  'it': 1,\n",
              "  'sexual': 1},\n",
              " 'sexing': {},\n",
              " 'slutt': {},\n",
              " 'titlicker': {},\n",
              " 'kunnilingus': {},\n",
              " 'fuckwhore': {},\n",
              " 'wet dream': {},\n",
              " 'spunk': {},\n",
              " 'pisser': {},\n",
              " 'puss': {},\n",
              " 'boner': {'a': 2,\n",
              "  'masturbate': 2,\n",
              "  'hangups': 2,\n",
              "  'blowjob': 2,\n",
              "  'nudist': 2,\n",
              "  'hots': 1,\n",
              "  'orgasm': 1,\n",
              "  'cunt': 1,\n",
              "  'viagra': 1,\n",
              "  'panty': 1},\n",
              " 'skeet': {},\n",
              " 'sextoys': {},\n",
              " 'vibrator': {},\n",
              " 'manpaste': {},\n",
              " 'faggot': {'scumbag': 126,\n",
              "  'fags': 16,\n",
              "  'whiny': 7,\n",
              "  'cocksucker': 6,\n",
              "  'stooge': 6,\n",
              "  'dumfuck': 4,\n",
              "  'mongoose': 3,\n",
              "  'cuckold': 2,\n",
              "  'flake': 2,\n",
              "  'nigger': 2},\n",
              " 'humping': {'larping': 2,\n",
              "  'drinking': 1,\n",
              "  'piss': 1,\n",
              "  'wacking': 1,\n",
              "  'forestbathing': 1,\n",
              "  'worshipping': 1,\n",
              "  'peddling': 1,\n",
              "  'licking': 1,\n",
              "  'sucking': 1},\n",
              " 'nipple': {},\n",
              " 'double penetration': {},\n",
              " 'coons': {'coozes': 4,\n",
              "  'ghoulies': 4,\n",
              "  'faggots': 3,\n",
              "  'coote': 2,\n",
              "  'nuffins': 2,\n",
              "  'wignats': 2,\n",
              "  'cuck': 1,\n",
              "  'lol': 1,\n",
              "  'cucks': 1,\n",
              "  'cooties': 1},\n",
              " 'assklown': {},\n",
              " 'pubes': {'penises': 2, 'genitalia': 1, 'vaginas': 1, 'genitals': 1},\n",
              " 'fuckface': {},\n",
              " 'anal': {'sexual': 11,\n",
              "  'penis': 2,\n",
              "  'sexually': 2,\n",
              "  'sex': 1,\n",
              "  'oral': 1,\n",
              "  'probe': 1,\n",
              "  'piss': 1,\n",
              "  'rimming': 1},\n",
              " 'nimphomania': {},\n",
              " 'blowjob': {'boner': 2,\n",
              "  'masturbate': 2,\n",
              "  'cunt': 2,\n",
              "  'rapefugees': 1,\n",
              "  'boob': 1,\n",
              "  'wackjobs': 1,\n",
              "  'trazzle': 1},\n",
              " 'rimjob': {},\n",
              " 'fisting': {},\n",
              " 'niggardliness': {},\n",
              " 'sultry women': {},\n",
              " 'jizzim': {},\n",
              " 'kinkster': {},\n",
              " 'skankfuck': {},\n",
              " 'penis': {'cock': 27,\n",
              "  'dick': 27,\n",
              "  'dickcam': 6,\n",
              "  'trump': 3,\n",
              "  'vagina': 2,\n",
              "  'literal': 1,\n",
              "  'pepsi': 1,\n",
              "  'homosexual': 1,\n",
              "  'micro': 1,\n",
              "  'gay': 1},\n",
              " 'how to kill': {},\n",
              " 'semen': {},\n",
              " 'mothafucker': {},\n",
              " 'analsex': {},\n",
              " 'niggur': {},\n",
              " 'panty': {'genitals': 3,\n",
              "  'dick': 2,\n",
              "  'mangina': 1,\n",
              "  'penis': 1,\n",
              "  'tush': 1,\n",
              "  'dickcam': 1,\n",
              "  'masculinity': 1},\n",
              " 'deep throat': {},\n",
              " 'foot fetish': {},\n",
              " 'freakyfucker': {},\n",
              " 'date rape': {},\n",
              " 'assblaster': {},\n",
              " 'bukkake': {},\n",
              " 'lesbo': {},\n",
              " 'spaghettinigger': {},\n",
              " 'beaner': {},\n",
              " 'clover clamps': {},\n",
              " 'twobitwhore': {},\n",
              " 'nigr': {},\n",
              " 'fuckfriend': {},\n",
              " 'sextoy': {},\n",
              " 'prostitute': {'whore': 5},\n",
              " 'pussyfucker': {},\n",
              " 'kanake': {},\n",
              " 'porchmonkey': {},\n",
              " 'testicles': {},\n",
              " 'erotism': {},\n",
              " 'pusy': {},\n",
              " 'assjockey': {},\n",
              " 'pimpjuic': {},\n",
              " 'booty call': {},\n",
              " 'kaffir': {},\n",
              " 'fuckable': {},\n",
              " 'goldenshower': {},\n",
              " 'homobangers': {},\n",
              " 'pegging': {},\n",
              " 'rapist': {'raping': 14,\n",
              "  'molester': 6,\n",
              "  'molestors': 4,\n",
              "  'assault': 3,\n",
              "  'rape': 2,\n",
              "  'satanist': 2,\n",
              "  'sexually': 2,\n",
              "  'molested': 2,\n",
              "  'psychopath': 1,\n",
              "  'fetishists': 1},\n",
              " 'venus mound': {},\n",
              " 'raping': {'rape': 16,\n",
              "  'abusing': 9,\n",
              "  'rapist': 7,\n",
              "  'pimping': 5,\n",
              "  'pillating': 4,\n",
              "  'beat': 3,\n",
              "  'molested': 3,\n",
              "  'molesting': 3,\n",
              "  'rapes': 3,\n",
              "  'killing': 2},\n",
              " 'fudge packer': {},\n",
              " 'sexcam': {},\n",
              " 'timbernigger': {},\n",
              " 'viagra': {'boner': 2, 'herpes': 1, 'hangover': 1, 'pedophilia': 1},\n",
              " 'make me come': {},\n",
              " 'beastiality': {},\n",
              " 'leather restraint': {},\n",
              " 'coon': {},\n",
              " 'futanari': {'hentai': 3, 'yori': 1, 'kasumi': 1},\n",
              " 'fuckina': {},\n",
              " 'iblowu': {},\n",
              " 'masterbate': {},\n",
              " 'luckycammeltoe': {},\n",
              " \"niggardliness's\": {},\n",
              " 'fuckmehard': {},\n",
              " 'tits': {'boobs': 6,\n",
              "  'breasts': 3,\n",
              "  'nipples': 3,\n",
              "  'pantys': 2,\n",
              "  'panties': 1,\n",
              "  'penises': 1,\n",
              "  'pussy': 1,\n",
              "  'breast': 1,\n",
              "  'waists': 1,\n",
              "  'body': 1},\n",
              " 'suckme': {},\n",
              " 'intheass': {},\n",
              " 'niggarding': {},\n",
              " 'tonguetramp': {},\n",
              " 'niggor': {},\n",
              " 'schlong': {'schmekel': 2, 'schlomo': 2, 'schnoz': 1},\n",
              " 'niggah': {},\n",
              " 'raped': {'assaulted': 83,\n",
              "  'raping': 31,\n",
              "  'rapes': 19,\n",
              "  'violated': 9,\n",
              "  'sexually': 6,\n",
              "  'molested': 6,\n",
              "  'tortured': 6,\n",
              "  'attacked': 5,\n",
              "  'beaten': 5,\n",
              "  'assault': 4},\n",
              " 'nazi': {'hitler': 43,\n",
              "  'jew': 7,\n",
              "  'german': 7,\n",
              "  'fascist': 4,\n",
              "  'debate': 4,\n",
              "  'concentration': 3,\n",
              "  '’': 3,\n",
              "  'communist': 3,\n",
              "  'holocaust': 2,\n",
              "  'socialist': 2},\n",
              " 'two girls one cup': {},\n",
              " 'huge fat': {},\n",
              " 'upthebutt': {},\n",
              " 'daterape': {},\n",
              " 'mastabater': {},\n",
              " 'cum': {'fuck': 3,\n",
              "  'dem': 2,\n",
              "  '&': 2,\n",
              "  'soy': 2,\n",
              "  'dickcam': 2,\n",
              "  'bitchute': 2,\n",
              "  'awsome': 1,\n",
              "  'sham': 1,\n",
              "  'sexual': 1,\n",
              "  'sup': 1},\n",
              " 'asslick': {},\n",
              " 'raghead': {},\n",
              " 'bestiality': {},\n",
              " 'golden shower': {},\n",
              " 'niggers': {'racists': 38,\n",
              "  'niggas': 17,\n",
              "  'negros': 17,\n",
              "  'chimps': 9,\n",
              "  'chinks': 9,\n",
              "  'bigots': 7,\n",
              "  'faggots': 7,\n",
              "  'pedophiles': 5,\n",
              "  'gentiles': 4,\n",
              "  'gays': 4},\n",
              " 'penises': {'genitals': 4,\n",
              "  'vaginas': 3,\n",
              "  'pantys': 2,\n",
              "  'nipples': 1,\n",
              "  'cock': 1,\n",
              "  'vagina': 1,\n",
              "  'boobs': 1,\n",
              "  'pubes': 1,\n",
              "  'small': 1},\n",
              " 'mufflikcer': {},\n",
              " 'camel toe': {},\n",
              " 'shaved pussy': {},\n",
              " 'niggles': {},\n",
              " 'jijjiboo': {}}"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('hello')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPd_V9B3NTxT",
        "outputId": "977054ef-6181-4639-dc82-5f18d3067e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LBv95lL_WMy"
      },
      "source": [
        "# query homonymous words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLRC0Cliub2l"
      },
      "source": [
        "Now see how it works: \n",
        "\n",
        "* if the word \"bank\" is in context of \"power bank\", then the nearest neighbor is a \"power bank\" as well.\n",
        "\n",
        "* if the word \"bank\" is in context of \"investment bank\", then the nearest neighbor is a \"bank\" as well, but in financial context\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Siy9GwPdqYN1"
      },
      "source": [
        "distances, neighbors, contexts = storage.query(query_sent='It is a power bank.', query_word='bank', k=5)\n",
        "for d, w, c in zip(distances, neighbors, contexts):\n",
        "    print('{} {}  {}'.format(w, d, c.strip()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUyplIsorGcA"
      },
      "source": [
        "distances, neighbors, contexts = storage.query(query_sent='It is an investment bank.', query_word='bank', k=5)\n",
        "for d, w, c in zip(distances, neighbors, contexts):\n",
        "    print('{} {}  {}'.format(w, d, c.strip()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88A4TQdhvubC"
      },
      "source": [
        "If we look for the neighbors not containing the word \"bank\", then with investment context it is all about finance, but for \"power bank\" there are a few non-financial contexts. \n",
        "\n",
        "Probably, with a larger corpus, we would be able to find even more relevant examples (like \"battery\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doWA6h7ru1O-"
      },
      "source": [
        "distances, neighbors, contexts = storage.query(query_sent='It is an investment bank.', query_word='bank', k=5, filter_same_word=True)\n",
        "total = 0\n",
        "for d, w, c in zip(distances, neighbors, contexts):\n",
        "    print('{} {}  {}'.format(w, d, c.strip()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa9fI8Q8u7qz"
      },
      "source": [
        "distances, neighbors, contexts = storage.query(query_sent='It is a power bank.', query_word='bank', k=5, filter_same_word=True)\n",
        "total = 0\n",
        "for d, w, c in zip(distances, neighbors, contexts):\n",
        "    print('{} {}  {}'.format(w, d, c.strip()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctizE_Kt_mVs"
      },
      "source": [
        "For a \"river bank\", there are no relevant examples in our small corpus (10k sentences only), but the result is still not completely meaningless (e.g. \"river side\" is related to \"river bank\")."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aIQGBJq_cVk"
      },
      "source": [
        "distances, neighbors, contexts = storage.query(query_sent='It is a river bank.', query_word='bank', k=5, filter_same_word=True)\n",
        "total = 0\n",
        "for d, w, c in zip(distances, neighbors, contexts):\n",
        "    print('{} {}  {}'.format(w, d, c.strip()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmse5KnI_QxR"
      },
      "source": [
        "# query named entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlPavawt47Vx"
      },
      "source": [
        "Now let's try a query with named entity. We can see that Amazon the company and Amazon the toponym have nearest neighbors which are a company and a toponym as well. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEEndzzI0s4P"
      },
      "source": [
        "s = \"Bezos announced that its two-day delivery service, Amazon Prime, had surpassed 100 million subscribers worldwide.\"\n",
        "distances, neighbors, contexts = storage.query(query_sent=s, query_word='amazon', k=5)\n",
        "for d, w, c in zip(distances, neighbors, contexts):\n",
        "    print('{} {}  {}'.format(w, d, c.strip()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kgx-_aKp5AyN"
      },
      "source": [
        "s = \"The Atlantic has sufficient wave and tidal energy to carry most of the Amazon's sediments out to sea, thus the river does not form a true delta\"\n",
        "distances, neighbors, contexts = storage.query(query_sent=s, query_word='amazon', k=5)\n",
        "for d, w, c in zip(distances, neighbors, contexts):\n",
        "    print('{} {}  {}'.format(w, d, c.strip()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8BpB0He-faY"
      },
      "source": [
        "Moreover, we can infer that Amazon the company is related to Google, Alexa and Netflix, whereas Amazon the river is related to Brazil and the Brazilian city Belem. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTv33CPs5C_g"
      },
      "source": [
        "s = \"Bezos announced that its two-day delivery service, Amazon Prime, had surpassed 100 million subscribers worldwide.\"\n",
        "distances, neighbors, contexts = storage.query(query_sent=s, query_word='amazon', k=5, filter_same_word=True)\n",
        "for d, w, c in zip(distances, neighbors, contexts):\n",
        "    print('{} {}  {}'.format(w, d, c.strip()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTBlcG9V-bQM"
      },
      "source": [
        "s = \"The Atlantic has sufficient wave and tidal energy to carry most of the Amazon's sediments out to sea, thus the river does not form a true delta\"\n",
        "distances, neighbors, contexts = storage.query(query_sent=s, query_word='amazon', k=5, filter_same_word=True)\n",
        "for d, w, c in zip(distances, neighbors, contexts):\n",
        "    print('{} {}  {}'.format(w, d, c.strip()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0lLzMKJ-qj1"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}